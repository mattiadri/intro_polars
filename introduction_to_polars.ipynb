{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intoduction to Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://realpython.com/python-gil/\n",
    "\n",
    "https://pola.rs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/polars.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The versatility of Python and its simple syntax are certainly the strong points of this high-level, general-purpose programming language. However, one of its greatest weaknesses, if not the greatest (especially considering how the computing ecosystem has evolved), is the Global Interpreter Lock (GIL)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python Global Interpreter Lock, or GIL, is a mutex (lock) that permits only one thread to control the Python interpreter at a time. In simple terms, it means that only one thread can be actively executing code at any given moment. While this constraint may not be noticeable in single-threaded programs, it can become a performance bottleneck in scenarios involving multi-threaded code or CPU-bound tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GIL's reputation as an \"infamous\" feature stems from its restriction of executing only one thread at a time, even in multi-threaded architectures with multiple CPU cores. This article explores how the GIL affects the performance of Python programs and provides insights into mitigating its impact on code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the problem the GIL addresses, it's crucial to delve into Python's memory management using reference counting. Objects in Python have a reference count variable that tracks the number of references pointing to the object. When this count reaches zero, the object's memory is released. The GIL addresses the challenge of protecting this reference count variable from race conditions where two threads might simultaneously increase or decrease its value. Without proper protection, such scenarios could lead to memory leaks or, worse, incorrect release of memory while references to the object still exist, resulting in crashes or unpredictable bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "a = []\n",
    "b = a\n",
    "sys.getrefcount(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While one solution could be adding locks to shared data structures to safeguard the reference count variable, it introduces the risk of deadlocks and performance degradation due to repeated lock acquisition and release. The GIL takes a different approach by acting as a single lock on the interpreter itself. This ensures that executing any Python bytecode necessitates acquiring the interpreter lock. Although this approach avoids deadlocks and minimizes performance overhead, it effectively confines CPU-bound Python programs to single-threaded execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is a high-level programming language that prioritizes ease of use and readability. However, this focus on simplicity and readability can impact its performance. Recognizing the need for optimized execution in certain scenarios, an interface between Python and C has been developed. This integration allows developers to leverage the efficiency of C, a low-level language known for its speed, in performance-critical sections of their Python programs. By doing so, they can strike a balance between Python's simplicity and C's performance, optimizing their applications for specific tasks. Interestingly, the GIL was not only designed to ensure better performance in single-threaded programs but also to facilitate the integration of C libraries that were not thread-safe. It's amusing to note that in C, you can sidestep the issue of individual threads, and this playful workaround extends to other programming languages as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those clever creators of Polars wrote the library in Rust. In addition to this, they focused on parallelization and efficiency. And given the excellent result, Polars will probably replace Pandas in the course of a few years. Therefore, in this course, we explore a bit of this fantastic library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import polars as pl\n",
    "except ImportError:\n",
    "    print(\"Il pacchetto 'polars' non è installato. Installazione in corso...\")\n",
    "    %conda install -c conda-forge polars -y\n",
    "    print(\"Installazione completata.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polars is entirely based on Arrow data types and backed by Arrow memory arrays. From this point of view, there isn't much new, but it's worth listing the types we will use the most:\n",
    "\n",
    "* ```pl.Int32``` and ```pl.Int64```\n",
    "* ```pl.Float32``` and ```pl.Float32```\n",
    "* ```pl.Date``` and ```pl.Datetime```\n",
    "* ```pl.Boolean``` and ```pl.Categorical```\n",
    "\n",
    "Categorical data represents string data where the values in the column have a finite set of values. Storing these values as plain strings is a waste of memory so Polars encode them in dictionary format.\n",
    "\n",
    "Keep in mind that in Polars, 'NaN' doesn't exist; instead, it is replaced with ```pl.Null```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the structures, they are similar to those in Pandas, so essentially, we will be working with:\n",
    "* ```pl.Series``` and  ```pl.DataFrame```\n",
    "\n",
    "Some of these functions have been implemented and operate for ```pl.DataFrame``` in the same way as those in Pandas:\n",
    "\n",
    "* ```.head()``` shows the first 5 elements\n",
    "* ```.tail()``` shows the last 5 elements\n",
    "* ```.sample()``` shows 5 random elements\n",
    "* ```.describe()``` returns summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polars supports reading and writing to all common files (e.g. csv, json, parquet), cloud storage (S3, Azure Blob, BigQuery) and databases (e.g. postgres, mysql). For this course, we are revisiting the old and dear Titanic database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(\"titanic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the syntax is quite simple: use ```read_filetype``` for reading and ```write_filetype``` for writing. I would refer you to the documentation for the attributes of the aforementioned functions. A non-exhaustive list of file types includes:\n",
    "* ```.read_json()``` and ```.write_json()```\n",
    "* ```.read_parquet()``` and ```.write_parquet()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contexts and Expressions constitute the language through which Polars performs operations on data. A context pertains to the circumstances under which an expression is meant to be assessed. Let's do some examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the ```select``` context the selection applies expressions over columns. The expressions in this context must produce Series that are all the same length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌───────────────────────────────────┬──────┬──────────┐\n",
      "│ Name                              ┆ Age  ┆ Survived │\n",
      "│ ---                               ┆ ---  ┆ ---      │\n",
      "│ str                               ┆ f64  ┆ i64      │\n",
      "╞═══════════════════════════════════╪══════╪══════════╡\n",
      "│ Braund, Mr. Owen Harris           ┆ 22.0 ┆ 0        │\n",
      "│ Cumings, Mrs. John Bradley (Flor… ┆ 38.0 ┆ 1        │\n",
      "│ Heikkinen, Miss. Laina            ┆ 26.0 ┆ 1        │\n",
      "│ Futrelle, Mrs. Jacques Heath (Li… ┆ 35.0 ┆ 1        │\n",
      "│ Allen, Mr. William Henry          ┆ 35.0 ┆ 0        │\n",
      "└───────────────────────────────────┴──────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "out = df.select(pl.col(\"Name\"),\n",
    "                pl.col(\"Age\"),\n",
    "                pl.col(\"Survived\")\n",
    "                ).limit(5)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```select``` is very similar to ```with_columns``` The main difference is that the latter retains the original columns and adds new ones while ```select``` drops the original columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌───────────────────────────────────┬──────┬──────────┬─────────┐\n",
      "│ Name                              ┆ Age  ┆ Survived ┆ As bool │\n",
      "│ ---                               ┆ ---  ┆ ---      ┆ ---     │\n",
      "│ str                               ┆ f64  ┆ i64      ┆ bool    │\n",
      "╞═══════════════════════════════════╪══════╪══════════╪═════════╡\n",
      "│ Braund, Mr. Owen Harris           ┆ 22.0 ┆ 0        ┆ false   │\n",
      "│ Cumings, Mrs. John Bradley (Flor… ┆ 38.0 ┆ 1        ┆ true    │\n",
      "│ Heikkinen, Miss. Laina            ┆ 26.0 ┆ 1        ┆ true    │\n",
      "│ Futrelle, Mrs. Jacques Heath (Li… ┆ 35.0 ┆ 1        ┆ true    │\n",
      "│ Allen, Mr. William Henry          ┆ 35.0 ┆ 0        ┆ false   │\n",
      "└───────────────────────────────────┴──────┴──────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "out = out.with_columns(pl.col(\"Survived\").cast(pl.Boolean).alias(\"As bool\"))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the filter context you filter the existing dataframe based on arbitrary expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 12)\n",
      "┌─────────────┬──────────┬────────┬──────────────────┬───┬─────────┬─────────┬───────┬──────────┐\n",
      "│ PassengerId ┆ Survived ┆ Pclass ┆ Name             ┆ … ┆ Ticket  ┆ Fare    ┆ Cabin ┆ Embarked │\n",
      "│ ---         ┆ ---      ┆ ---    ┆ ---              ┆   ┆ ---     ┆ ---     ┆ ---   ┆ ---      │\n",
      "│ i64         ┆ i64      ┆ i64    ┆ str              ┆   ┆ str     ┆ f64     ┆ str   ┆ str      │\n",
      "╞═════════════╪══════════╪════════╪══════════════════╪═══╪═════════╪═════════╪═══════╪══════════╡\n",
      "│ 8           ┆ 0        ┆ 3      ┆ Palsson, Master. ┆ … ┆ 349909  ┆ 21.075  ┆ null  ┆ S        │\n",
      "│             ┆          ┆        ┆ Gosta Leonard    ┆   ┆         ┆         ┆       ┆          │\n",
      "│ 11          ┆ 1        ┆ 3      ┆ Sandstrom, Miss. ┆ … ┆ PP 9549 ┆ 16.7    ┆ G6    ┆ S        │\n",
      "│             ┆          ┆        ┆ Marguerite Rut   ┆   ┆         ┆         ┆       ┆          │\n",
      "│ 17          ┆ 0        ┆ 3      ┆ Rice, Master.    ┆ … ┆ 382652  ┆ 29.125  ┆ null  ┆ Q        │\n",
      "│             ┆          ┆        ┆ Eugene           ┆   ┆         ┆         ┆       ┆          │\n",
      "│ 25          ┆ 0        ┆ 3      ┆ Palsson, Miss.   ┆ … ┆ 349909  ┆ 21.075  ┆ null  ┆ S        │\n",
      "│             ┆          ┆        ┆ Torborg Danira   ┆   ┆         ┆         ┆       ┆          │\n",
      "│ 51          ┆ 0        ┆ 3      ┆ Panula, Master.  ┆ … ┆ 3101295 ┆ 39.6875 ┆ null  ┆ S        │\n",
      "│             ┆          ┆        ┆ Juha Niilo       ┆   ┆         ┆         ┆       ┆          │\n",
      "└─────────────┴──────────┴────────┴──────────────────┴───┴─────────┴─────────┴───────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "out = df.filter((pl.col(\"Age\") < 10) & (pl.col(\"Pclass\") == 3)).limit(5)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Group by with aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the ```group_by``` context, expressions work on groups and thus can yield results of any length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 4)\n",
      "┌────────┬─────┬─────────────────┬──────────┐\n",
      "│ Pclass ┆ #   ┆ ids of Johns    ┆ Survived │\n",
      "│ ---    ┆ --- ┆ ---             ┆ ---      │\n",
      "│ i64    ┆ u32 ┆ list[i64]       ┆ i64      │\n",
      "╞════════╪═════╪═════════════════╪══════════╡\n",
      "│ 3      ┆ 491 ┆ [9, 46, … 889]  ┆ 119      │\n",
      "│ 2      ┆ 184 ┆ [42, 99, … 865] ┆ 87       │\n",
      "│ 1      ┆ 216 ┆ [2, 169, … 823] ┆ 136      │\n",
      "└────────┴─────┴─────────────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "out = df.group_by(\"Pclass\").agg(\n",
    "    pl.count(\"PassengerId\").alias(\"#\"),\n",
    "    pl.col(\"PassengerId\").filter(pl.col(\"Name\").str.contains(\"John\")).alias(\"ids of Johns\"),\n",
    "    pl.sum(\"Survived\")\n",
    ")\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
